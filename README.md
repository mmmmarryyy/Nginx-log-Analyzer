# Проект 3: Анализатор логов

## Описание

Лог-файлы являются важной частью работы любого сервера, так как они содержат информацию о том, какие запросы были отправлены на сервер, какие ошибки возникли и какие действия были выполнены.  
Однако, обрабатывать и анализировать эти логи вручную может быть очень трудоемким процессом. Для решения этой проблемы напишем программу-анализатор логов.  
На вход программе через аргументы командной строки задаётся:
- путь к одному или нескольким **NGINX** лог-файлам в виде локального шаблона или **URL**
- необязательные временные параметры **from** и **to** в формате [ISO8601](https://ru.wikipedia.org/wiki/ISO_8601)
- необязательный параметр формата вывода результата: **markdown** или **adoc**

Примеры вызова программы:
```
analyzer --path logs/2024* --from 2024-08-31 --format markdown

analyzer --path https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/nginx_logs/nginx_logs --format adoc

analyzer --path logs/**/2024-08-31.txt
```

Программа должна выполнять следующие задачи:
- Подсчитывать общее количество запросов
- Определять наиболее часто запрашиваемые ресурсы
- Определять наиболее часто встречающиеся коды ответа
- Рассчитывать средний размер ответа сервера

## Функциональные требования

1. Программа должна принимать на вход путь к лог-файлам, который может быть шаблоном для локальных файлов или URL.
2. Программа должна поддерживать опциональные параметры:
   - from и to для анализа записей в заданном временном диапазоне
   - выходной формат данных в виде markdown или adoc документа
3. Функции программы:
   - Подсчитывает общее количество запросов
   - Определяет наиболее часто запрашиваемые ресурсы
   - Определяет наиболее часто встречающиеся коды ответа
   - Рассчитывает средний размер ответа сервера
   - Рассчитывает 95% перцентиль размера ответа сервера

## Нефункциональные требования

1. Программа должна обрабатывать лог-файлы эффективно, не загружая весь файл в память.
2. Код должен быть написан ясно и структурировано в соответствии с требованиями, указанными в разделе "Требования к ДЗ" информационного блока. 
3. Программа должна иметь четкую и понятную логику обработки ошибок.
4. Результат работы программы должен быть легко интерпретируемым человеком.

## Требования к ДЗ на scala
- Переменные и функции должны иметь осмысленные названия;
- Тест классы именуются <ClassName>Spec, где <ClassName> - класс к которому пишутся тесты;
- Тест классы находятся в том же пакете, что и класс к которому пишутся тесты (например, класс Fibonacci находится в пакете fibonacci в директории src/main/scala/fibonacci, значит его тест класс FibonacciSpec должен быть в том же пакете в директории src/test/scala/fibonacci);
- Каждый тест должен быть в отдельном test suite;
- Использовать java коллекции запрещается (Используйте Scala коллекции);
- Использовать mutable коллекции запрещается;
- Использовать var запрещается;
- Использование this запрещается (используйте self, если надо);
- Использование return запрещается;
- Использование System.exit запрещается;
- Касты или проверки на типы с помощью методов из Java вроде asInstanceOf запрещаются;
- Использование циклов запрещается (используйте for comprehension, tailRec, методы Monad, fold);
- Использование небезопасных вызовов разрешено только в тестах (например .get у Option);
- Использование взятия и освобождения примитивов синхронизации: semaphore, mutex - из разных потоков запрещено;
- Использование require для ошибок запрещается

## Описание входных и выходных данных
### Ввод
- Путь к лог-файлам: локальный путь или URL.
- Временные параметры: `from` и `to` в формате ISO8601 (опционально).
- Формат вывода: `markdown` или `adoc` (опционально).

### Вывод
- Текстовый отчёт в выбранном формате с анализом логов.

#### Пример вывода

```
#### Общая информация

|        Метрика        |     Значение |
|:---------------------:|-------------:|
|       Файл(-ы)        | `access.log` |
|    Начальная дата     |   31.08.2024 |
|     Конечная дата     |            - |
|  Количество запросов  |       10_000 |
| Средний размер ответа |         500b |
|   95p размера ответа  |         950b |

#### Запрашиваемые ресурсы

|     Ресурс      | Количество |
|:---------------:|-----------:|
|  `/index.html`  |      5_000 |
|  `/about.html`  |      2_000 |
| `/contact.html` |      1_000 |

#### Коды ответа

| Код |          Имя          | Количество |
|:---:|:---------------------:|-----------:|
| 200 |          OK           |       8000 |
| 404 |       Not Found       |       1000 |
| 500 | Internal Server Error |        500 |
```

## Инструкции по реализации

1. Разработайте парсер логов, который преобразует каждую строку лога в объект с полями, соответствующими структуре NGINX лог-файлов.
2. Реализуйте фильтрацию логов по временному диапазону, если таковые параметры предоставлены.
3. Соберите статистику по ключевым показателям: общее количество запросов, наиболее запрашиваемые ресурсы, коды ответов, средний размер ответа.
4. Форматирование результатов в markdown или adoc согласно предложенному шаблону.
5. Реализуйте функцию чтения лог-файлов, способную обработать как локальные файлы, так и загрузить данные с URL.

В конечном счете у вас должен получиться конвейер:
```
user input (file names, URL, etc) => Stream<LogRecord> => LogReport => текстовый отчёт в формате .md/.adoc
```

### Схема NGINX-логов

```
'$remote_addr - $remote_user [$time_local] ' '"$request" $status $body_bytes_sent ' '"$http_referer" "$http_user_agent"'
```

Примеры логов можно взять по [ссылке](https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/nginx_logs/nginx_logs) или создать самостоятельно:
```
docker run --rm -it -e 'RATE=10000' kscarlett/nginx-log-generator >> $HOME/logs.txt
```

После запуска подождите какое-то время (5-10с) и отправьте завершающий сигнал (Ctrl+C). Ваши логи будут в файле $HOME/logs.txt

### Описание кодов HTTP протокола

https://developer.mozilla.org/en-US/docs/Web/HTTP/Status

## Тестирование

1. Проверка чтения файлов по локальному пути и через URL.
2. Тестирование парсера логов на корректность разбора формата логов.
3. Проверка фильтрации по временному диапазону на различных случаях.
4. Тесты для подсчета статистики, проверяющие правильность расчетов.
5. Валидация формата и содержимого выходного отчета.

## Ограничения и советы

- Совет: обратите внимание на формат логов NGINX и убедитесь, что ваш парсер может обрабатывать стандартный формат
- Ограничение: используйте потоковую обработку данных для работы с лог-файлами для уменьшения потребления памяти
- Ограничение: вся статистика должна собираться за один проход по данным
- Ограничение: логи нужно трансформировать в типизированное промежуточное представление
- Ограничение: для работы с датами можно использовать современные классы для работы со временем и путями
- Ограничение: для сбора статистики используйте коллекции, например, список или словарь

## Критерии оценки
За задание можно получить 100 баллов.
- +5 бонусных баллов, если реализуете 1 дополнительную статистику (максимум +10 баллов) - done
- +15 бонусных баллов, если реализуете поддержку фильтрации логов по значению, например: - done
    ```
    analyzer --path logs/2024* --filter-field agent --filter-value "Mozilla*"
    ```
  или
    ```
    analyzer --path logs/2024* --filter-field method --filter-value "GET"
    ```